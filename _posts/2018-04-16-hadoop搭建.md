---
layout: original
title: "Hadoop分布式系统搭建流程"
date: 2018-05-06 14:00:00 +0800 
categories: 实用技术
tags: Hadoop
---
* content
{:toc}


>  以下是Hadoop伪分布式安装和配置流程。
<br/> JAVA版本：1.8.0
<br/> Hadoop版本： 2.7.1


<!-- more -->


##	安装JDK
版本要求： 1.7即以上。
```
sudo apt install openjdk-8-jdk
```	
之后配置JAVA_HOME:
```
vim /etc/environment
```
添加：`JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"`

## 	下载Hadoop 
网址：[Hadoop Releases](http://archive.apache.org/dist/hadoop/common/)

选择最新版本或稳定版本，以下过程以2.7.1版本为例。

## 	创建Hadoop用户
此步可省略，不过还是建议为Hadoop单独创建一个用户 和 用户组。		
```
groupadd hadoop-user
useradd -g hadoop-user -d /home/hadoop hadoop
passwd hadoop
```

## 	进入hadoop用户
```
su - hadoop
```
之后都是在hadoop用户下操作。

## 	安装/解压 Hadoop
```
mkdir hadoop_install 
```
将hadoop安装包放到该文件下,然后解压
```
tar -zxvf hadoop-2.7.1.tar.gz 
```
## 	配置环境变量
```
vim ~/.bash_profile
```
内容如下：
```	
HADOOP_HOME=/home/hadoop/hadoop_install/hadoop-2.7.1
CLASSPATH=$JAVA_HOME/lib
PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
## 	配置ssh免密访问
```
ssh-keygen -t rsa -P ""
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```
用以下命令测试ssh免密访问是否配置成功：
```
ssh localhost
```
如果不需要输入密码就可进入则配置成功。

注意：ssh服务需要主系统安装ssh-server:
```	
ssh apt install openssh-server
```

## 	配置Hadoop
Hadoop常用的配置文件有4个：`core-site.xml` 、`hdfs-site.xml`、 `mapred-site.xml`、 `yarn-site.xml`。
1. core-site.xml
主要完成NameNode的IP和端口设置。
```
<configuration>
    <!--指定namenode的地址-->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
    
    <!--用来指定使用hadoop时产生文件的存放目录-->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/home/hadoop/hadoop_install/hadoop-2.7.1/tmp</value> 
    </property>
 </configuration>
```

2. hdfs-site.xml
主要挖出HDFS数据块副本等参数设置。
```
<configuration>
    <!--指定hdfs保存数据的副本数量-->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>

    <!--指定hdfs中namenode的存储位置-->
    <property>
        <name>dfs.namenode.name.dir</name> 
        <value>file:/home/hadoop/hadoop_install/hadoop-2.7.1/tmp/dfs/name</value>
    </property>

    <!--指定hdfs中datanode的存储位置-->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/home/hadoop/hadoop_install/hadoop-2.7.1/tmp/dfs/data</value>
    </property>

</configuration>
```

3. mapred-site.xml
主要完成mapreduce framework、jobhistory server的设置。
```
<configuration>
<!--告诉hadoop以后MR(Map/Reduce)运行在YARN上-->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

4. yarn-site.xml
主要完成reduceManager的主机名和服务的配置。
```
<configuration>
    <!--nomenodeManager获取数据的方式是shuffle-->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    
    <!--指定Yarn的老大(ResourceManager)的地址-->     
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>localhost</value>
    </property> 
    
    <!--Yarn打印工作日志-->    
    <property>    
        <name>yarn.log-aggregation-enable</name> 
        <value>true</value>    
    </property>

<configuration>
```


## 	格式化NameNode
只需要安装系统时执行一次。
```
hadoop namenode -format
```

## 启动和停止

每次重启系统后，均需手动开启Hadoop服务：
```
start-all.sh
```
检查是否正常启动：在命令行输入 `jps`

如果输出中有`ResourceManager`、`NodeManager`、`SecondaryNameNode`、`NameNode`、`DataNode`则说明HDFS和MapReduce均已正常启动。
	
停止:
```
stop-all.sh
```

##	测试是否正常启动
可以通过运行Hadoop自带的WordCount进行测试：
		
```
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount test-in test-out
```
其中test-in目录为输入数据，需要自己手动创建（如何创建请参考[Hadoop常用操作]()

test-out目录不能事先存在。
	
如果运行成功，在test-out文件夹下应该能找到结果数据。
	
